{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Getting Started"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hi, and welcome to the intro to search tutorial! This is gonna be fun. Let's start."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Information Retrieval"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We won't dwell on this much, but those studying how to search stuff with computers call what they study *information retrieval*. We'll introduce some of the standard terminology of information retrieval so you're familiar with it, but don't get too hung up on it. (Here's the first term! *Information Retrieval*. More on [Wikipedia](http://en.wikipedia.org/wiki/Information_retrieval) ;)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Documents"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Documents are the building blocks of any search engine. *Documents* are what you're searching. They can be documentation pages, books, chapters of books, or other semi-structured text. The goal of search is to allow one to run *queries* over the documents to find what you're looking for. There can be multiple pieces of data associated with each document, and those pieces of data can have different formats, text and datetimes for example. The definition of the different pieces of data that make up a document is called a **schema**."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Indexing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes the data we're searching is small enough that we can just scan the full data for matches every time. In that case, we can just use a *regular expression*. But we're not talking about *regexes* today. We're talking about the case when we want to search a larger amount of data, really fast, where scanning the entire dataset every time is too slow. That's where a different set of techniques come in, starting with *indexing*.\n",
      "\n",
      "Indexing is the process of taking *documents*, extracting the relevant terms from them, and creating a data structure that can then be used to quickly find the documents again. Here we're going to take a look at indexing a very small set of documents. What is the data structure that is produced? Later, we'll form *queries* against this data structure to help us find the documents we're looking for."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We're using the awesome-tastic search library `whoosh`. Give Matt Chaput a hug if you see him!\n",
      "import whoosh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# you can run this on the command line with `python index_small_example.py`\n",
      "%run index_small_example.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "updating existing index in 'ex_index'\n",
        "processing document 0; document contents: The quick brown fox jumps over the lazy dog.\n",
        "processing document 1; document contents: I love Python!\n",
        "processing document 2; document contents: http://www.python.org/\n",
        "processing document 3; document contents: I never want to send another email ever again.\n",
        "processing document 4; document contents: Email email email. Sooo many emails.\n",
        "done!\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OK, so what does the index look like? By default, whoosh creates the index in a directory structure on disk, though it can also\n",
      "# create temporary indexes in memory. Here's the index we created:\n",
      "! file ex_index/*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ex_index/MAIN_WRITELOCK:            empty\r\n",
        "ex_index/MAIN_f9t1kmj19xfij2l1.seg: data\r\n",
        "ex_index/_MAIN_1.toc:               data\r\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks like the indexes that `Whoosh` is generating for us are a bunch of binary data.\n",
      "\n",
      "`_MAIN_1.toc` is the TableOfContents file, which basically consists of some versioning info (so the format can change and whoosh can tell), a pickled version of the index's `schema`, and a list of its `segments`. For our example, the `schema` looks like this:\n",
      "\n",
      "    schema = Schema(id=ID(unique=True), content=TEXT)\n",
      "    \n",
      " Pretty simple, huh?\n",
      "\n",
      "`Segments` are the way that `whoosh` breaks up the meat of its index in order to make its operations fast. Here's what the `whoosh` source has to say about them:\n",
      "\n",
      "      Having multiple segments allows quick incremental indexing: just create a\n",
      "      new segment for the new documents, and have the index overlay the new\n",
      "      segment over previous ones for purposes of reading/search. \"Optimizing\"\n",
      "      the index combines the contents of existing segments into one (removing\n",
      "      any deleted documents along the way).\n",
      "      \n",
      "([More info about how fast Whoosh is](https://bitbucket.org/mchaput/whoosh/wiki/Benchmarks))\n",
      "\n",
      "But what exactly is stored inside of each `segment`, and how does that help us search documents?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# OK, let's get set up to take a look at the contents of the index!\n",
      "from whoosh.index import open_dir\n",
      "ix = open_dir('ex_index')\n",
      "print \"{} documents in index `ix`\".format(ix.doc_count())\n",
      "r = ix.reader()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5 documents in index `ix`\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now we can play around with the contents of the index! Here are some suggestions:\n",
      "print list(r.all_doc_ids())\n",
      "print list(r.all_terms())\n",
      "print list(r.postings('content', 'email').all_ids())\n",
      "# tuples of (fieldname, text, docnum, weight, valuestring)\n",
      "print list(r.iter_postings())\n",
      "# Full API at http://pythonhosted.org/Whoosh/api/reading.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0, 1, 2, 3, 4]\n",
        "[('content', 'again'), ('content', 'another'), ('content', 'brown'), ('content', 'dog'), ('content', 'email'), ('content', 'emails'), ('content', 'ever'), ('content', 'fox'), ('content', 'http'), ('content', 'jumps'), ('content', 'lazy'), ('content', 'love'), ('content', 'many'), ('content', 'never'), ('content', 'over'), ('content', 'python'), ('content', 'quick'), ('content', 'send'), ('content', 'sooo'), ('content', 'want'), ('content', 'www.python.org'), ('id', '0'), ('id', '1'), ('id', '2'), ('id', '3'), ('id', '4')]\n",
        "[3L, 4L]\n",
        "[('content', 'again', 3L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x07a.'), ('content', 'another', 3L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x04a.'), ('content', 'brown', 0L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x02a.'), ('content', 'dog', 0L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x07a.'), ('content', 'email', 3L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x05a.'), ('content', 'email', 4L, 3.0, '\\x00\\x00\\x00\\x03\\x80\\x02]q\\x01(K\\x00K\\x01K\\x01e.'), ('content', 'emails', 4L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x05a.'), ('content', 'ever', 3L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x06a.'), ('content', 'fox', 0L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x03a.'), ('content', 'http', 2L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x00a.'), ('content', 'jumps', 0L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x04a.'), ('content', 'lazy', 0L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x06a.'), ('content', 'love', 1L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x01a.'), ('content', 'many', 4L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x04a.'), ('content', 'never', 3L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x01a.'), ('content', 'over', 0L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x05a.'), ('content', 'python', 1L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x02a.'), ('content', 'quick', 0L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x01a.'), ('content', 'send', 3L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x03a.'), ('content', 'sooo', 4L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x03a.'), ('content', 'want', 3L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x02a.'), ('content', 'www.python.org', 2L, 1.0, '\\x00\\x00\\x00\\x01\\x80\\x02]q\\x01K\\x01a.'), ('id', '0', 0L, 1.0, None), ('id', '1', 1L, 1.0, None), ('id', '2', 2L, 1.0, None), ('id', '3', 3L, 1.0, None), ('id', '4', 4L, 1.0, None)]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Postings\n",
      "\n",
      "## TODO: wtf is that hex crap? maybe we should sub out this query with something less confusing?\n",
      "\n",
      "So *ids* are the documents IDs and *terms* are the words from the documents, that's pretty self-explanatory. But what's a *posting*? In the language of information retrieval, a *posting* really just means a document ID! And a *posting list* is a list of postings, mapped to a term in the index.\n",
      "\n",
      "But we haven't really talked about indexes yet. From the word, you might think you can think of an `index` the same way you think of the `index` in the back of a reference book. (They are the same word after all!) And that's *almost* correct. It turns out that what `whoosh` is actually creating is what's called an `inverted index`.\n",
      "\n",
      "When creating an inverted index for a set of documents, `whoosh` does some processing that creates something similar to a book index for those documents. For text, that means breaking the text up by possible search terms, which are usually words, and associating each word with the documents it appears in. `Whoosh` can then combine words that someone searches for and, combined with the index, fetch up the most relevant documents.\n",
      "\n",
      "We don't really need to think about postings to use `whoosh` at a high level, but it's useful to be familiar with the terminology, as it's part  of the vocabulary of information retrieval.\n",
      "\n",
      "## Tasks\n",
      "* Modify the simple schema to incorporate a new data type. How does this change the posting list?\n",
      "* What's the *weight* term in a posting? Where does it come from?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Querying"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, now that we know about indexes, we're going to introduce a larger data set so we can search it. This tutorial comes with a set of data generated from a subset of [Project Gutenberg](http://www.gutenberg.org/wiki/Main_Page). You should have pre-generated metadata and a search index for this data as a part of preparation for this tutorial. If you haven't yet, do it now! It takes a few minutes to run."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run extract_metadata.py\n",
      "%run index_gutentexts.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from whoosh.qparser import QueryParser\n",
      "gutenindex = open_dir(\"gutenindex\")\n",
      "qp = QueryParser(\"content\", schema=gutenindex.schema)\n",
      "q = qp.parse(\"women Boston\")\n",
      "with gutenindex.searcher() as s:\n",
      "    results = s.search(q)\n",
      "    print results\n",
      "    print len(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Top 10 Results for And([Term('content', u'women'), Term('content', u'boston')]) runtime=0.0105450153351>\n",
        "78\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see that when `whoosh` parsed the text query \"women Boston\" into its query representation, it interpreted it by splitting the query into the two individual words and combining those two with an *AND* boolean operator. [Here's a summary of whoosh's default query language: http://pythonhosted.org/Whoosh/querylang.html]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Relevance\n",
      "\n",
      "`Whoosh` returns search results sorted by *relevance*, most-relevant first. What does it mean by `relevance`? Sometimes the same word from the query appears multiple times in a given document. `Whoosh` then weights that document more in the results.\n",
      "\n",
      "`Whoosh` can also give different weightings to different fields, so e.g. it makes a bigger difference if a book's title matches the query than if the book text does."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Tasks\n",
      "* Play around with the query language. How can I search for...\n",
      "  * a specific title\n",
      "  * a specific title containing multiple words?\n",
      "  * wildcards\n",
      "  * an exact phrase?\n",
      "  \n",
      "* Modify the query program to search *all* fields by default (title/author/content/etc.). \n",
      " \n",
      "* Modify the query program to give much higher weight to titles and authors than to the text of the book.\n",
      "\n",
      "* Can you modify the query language to support using boolean operators in a different language? [This might help](http://pythonhosted.org/Whoosh/parsing.html)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Advanced Topics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is all on you. Here are some additional things to learn if you get this far. If you want some pointers or something explained, raise your hand and we'll help you out.\n",
      "\n",
      "### Sorting and faceting\n",
      "\n",
      "http://pythonhosted.org/Whoosh/facets.html\n",
      "\n",
      "### Spelling Correction\n",
      "\n",
      "Modify `query_webapp.py` to give mispelling suggestions if no results are found for a given search query.\n",
      "\n",
      "http://pythonhosted.org/Whoosh/keywords.html\n",
      "\n",
      "### Highlighting\n",
      "\n",
      "Modify `query_webapp.py` to serve up results with the search terms highlighted.\n",
      "\n",
      "http://pythonhosted.org/Whoosh/highlight.html\n",
      "\n",
      "### N-grams\n",
      "\n",
      "http://pythonhosted.org/Whoosh/ngrams.html"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print r.frequency('content', 'email')\n",
      "print list(r.expand_prefix('content', 'e'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4.0\n",
        "['email', 'emails', 'ever']\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Further Reading\n",
      "\n",
      "Kragen Sitaker is writing a tiny search engine in pure Python for the next edition of The Architecture of Open Source Applications book, which is a super great read if you're interested in the nitty gritty of the basic data structures behind indexing:\n",
      "\n",
      "https://github.com/kragen/500lines/tree/master/search-engine\n",
      "\n",
      "His \"Further information\" section contains a bunch of great resources for further study as well."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
